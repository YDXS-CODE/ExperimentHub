{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9829fbe",
   "metadata": {},
   "source": [
    "# AnimeGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8cbf0",
   "metadata": {},
   "source": [
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc389800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0382d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BaseOverlay(\"base.bit\")\n",
    "# monitor configuration: 640*480 @ 60Hz\n",
    "Mode = VideoMode(640,480,24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode,PIXEL_BGR)\n",
    "hdmi_out.start()\n",
    "# monitor (output) frame buffer size\n",
    "frame_out_w = 1920\n",
    "frame_out_h = 1080\n",
    "# camera (input) configuration\n",
    "frame_in_w = 640\n",
    "frame_in_h = 480\n",
    "# initialize camera from OpenCV\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "if(videoIn.isOpened()):\n",
    "    print(\"Capture device is open: \" + str(videoIn.isOpened()))\n",
    "    img = cv2.imread('/home/xilinx/jupyter_notebooks/AnimeGAN/开始界面.png')\n",
    "    #在图片上添加文字信息\n",
    "    frame = cv2.resize(img,(640,480))\n",
    "    # cv2.putText(frame, \"Hello Vertira\",(320, 240), cv2.FONT_HERSHEY_PLAIN, 2.0, (0, 0, 255), 2)\n",
    "    outframe = hdmi_out.newframe()\n",
    "    outframe[0:480,0:640,:] = frame[0:480,0:640,[0,1,2]]\n",
    "    hdmi_out.writeframe(outframe)\n",
    "else:\n",
    "    print(\"Capture device is open: \" + str(videoIn.isOpened()))\n",
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499acc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdmi_out.stop()\n",
    "#del hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c42695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/xilinx/jupyter_notebooks/AnimeGAN/开始界面.png')\n",
    "#在图片上添加文字信息\n",
    "frame = cv2.resize(img,(640,480))\n",
    "# cv2.putText(frame, \"Hello Vertira\",(320, 240), cv2.FONT_HERSHEY_PLAIN, 2.0, (0, 0, 255), 2)\n",
    "outframe = hdmi_out.newframe()\n",
    "outframe[0:480,0:640,:] = frame[0:480,0:640,[0,1,2]]\n",
    "hdmi_out.writeframe(outframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5de057",
   "metadata": {},
   "source": [
    "## 模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9107edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNormLReLU(nn.Sequential):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1, padding=1, pad_mode=\"reflect\", groups=1, bias=False):\n",
    "        \n",
    "        pad_layer = {\n",
    "            \"zero\":    nn.ZeroPad2d,\n",
    "            \"same\":    nn.ReplicationPad2d,\n",
    "            \"reflect\": nn.ReflectionPad2d,\n",
    "        }\n",
    "        if pad_mode not in pad_layer:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        super(ConvNormLReLU, self).__init__(\n",
    "            pad_layer[pad_mode](padding),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding=0, groups=groups, bias=bias),\n",
    "            nn.GroupNorm(num_groups=1, num_channels=out_ch, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "class InvertedResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, expansion_ratio=2):\n",
    "        super(InvertedResBlock, self).__init__()\n",
    "\n",
    "        self.use_res_connect = in_ch == out_ch\n",
    "        bottleneck = int(round(in_ch*expansion_ratio))\n",
    "        layers = []\n",
    "        if expansion_ratio != 1:\n",
    "            layers.append(ConvNormLReLU(in_ch, bottleneck, kernel_size=1, padding=0))\n",
    "        \n",
    "        # dw\n",
    "        layers.append(ConvNormLReLU(bottleneck, bottleneck, groups=bottleneck, bias=True))\n",
    "        # pw\n",
    "        layers.append(nn.Conv2d(bottleneck, out_ch, kernel_size=1, padding=0, bias=False))\n",
    "        layers.append(nn.GroupNorm(num_groups=1, num_channels=out_ch, affine=True))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.layers(input)\n",
    "        if self.use_res_connect:\n",
    "            out = input + out\n",
    "        return out\n",
    "\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block_a = nn.Sequential(\n",
    "            ConvNormLReLU(3,  32, kernel_size=7, padding=3),\n",
    "            ConvNormLReLU(32, 64, stride=2, padding=(0,1,0,1)),\n",
    "            ConvNormLReLU(64, 64)\n",
    "        )\n",
    "        #input [c,h,w]->[c,h+6,w+6]\n",
    "        \n",
    "        self.block_b = nn.Sequential(\n",
    "            ConvNormLReLU(64,  128, stride=2, padding=(0,1,0,1)),            \n",
    "            ConvNormLReLU(128, 128)\n",
    "        )\n",
    "        \n",
    "        self.block_c = nn.Sequential(\n",
    "            ConvNormLReLU(128, 128),\n",
    "            InvertedResBlock(128, 256, 2),\n",
    "            InvertedResBlock(256, 256, 2),\n",
    "            InvertedResBlock(256, 256, 2),\n",
    "            InvertedResBlock(256, 256, 2),\n",
    "            ConvNormLReLU(256, 128),\n",
    "        )    \n",
    "        \n",
    "        self.block_d = nn.Sequential(\n",
    "            ConvNormLReLU(128, 128),\n",
    "            ConvNormLReLU(128, 128)\n",
    "        )\n",
    "\n",
    "        self.block_e = nn.Sequential(\n",
    "            ConvNormLReLU(128, 64),\n",
    "            ConvNormLReLU(64,  64),\n",
    "            ConvNormLReLU(64,  32, kernel_size=7, padding=3)\n",
    "        )\n",
    "\n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input, align_corners=True):\n",
    "        print('-'*50)\n",
    "        print(\"begin 1\")\n",
    "        a = time.time()\n",
    "        s = a\n",
    "        out = self.block_a(input)\n",
    "        b = time.time()\n",
    "        print(\"block_a time\",b-a)\n",
    "        print(\"block_a size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 2\")\n",
    "        \n",
    "#         half_size = out.size()[-2:]\n",
    "#         print(\"begin 3\")\n",
    "        a = time.time()\n",
    "        out = self.block_b(out)\n",
    "        b = time.time()\n",
    "        print(\"block_b time\",b-a)\n",
    "        print(\"block_b size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 3\")\n",
    "        a = time.time()\n",
    "        out = self.block_c(out)\n",
    "        b = time.time()\n",
    "        print(\"block_c time\",b-a)\n",
    "        print(\"block_c size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 4\")\n",
    "        \n",
    "        a = time.time()\n",
    "        if align_corners:\n",
    "            out = F.interpolate(out, half_size, mode=\"bilinear\", align_corners=True)\n",
    "        else:\n",
    "            out = F.interpolate(out, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        b = time.time()\n",
    "        print(\"F.interpolate time\",b-a)\n",
    "        print(\"F.interpolate size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 5\")\n",
    "        a = time.time()\n",
    "        out = self.block_d(out)\n",
    "        b = time.time()\n",
    "        print(\"block_d time\",b-a)\n",
    "        print(\"block_d size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 6\")\n",
    "        \n",
    "        a = time.time()\n",
    "        if align_corners:\n",
    "            out = F.interpolate(out, input.size()[-2:], mode=\"bilinear\", align_corners=True)\n",
    "        else:\n",
    "            out = F.interpolate(out, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        b = time.time()\n",
    "        print(\"F.interpolate time\",b-a)\n",
    "        print(\"F.interpolate size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 7\")\n",
    "        img = cv2.imread('./等待界面2.png')\n",
    "        frame = cv2.resize(img,(640,480))\n",
    "        #要注意这里不是通过array或者list格式输出的，为video包中的专属格式\n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe[0:480,0:640,:] = frame[0:480,0:640,[0,1,2]]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "        a = time.time()\n",
    "        out = self.block_e(out)\n",
    "        b = time.time()\n",
    "        print(\"block_e time\",b-a)\n",
    "        print(\"block_e size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 8\")\n",
    "        \n",
    "        a = time.time()\n",
    "        out = self.out_layer(out)\n",
    "        b = time.time()\n",
    "        print(\"block_d time\",b-a)\n",
    "        print(\"block_d size\",out.shape)\n",
    "        print('-'*50)\n",
    "        print(\"begin 9\")\n",
    "        print(\"total time\",b-s)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53b8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, x32=False):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    if x32:\n",
    "        def to_32s(x):\n",
    "            return 256 if x < 256 else x - x % 32\n",
    "        w, h = img.size\n",
    "        img = img.resize((to_32s(w), to_32s(h)))\n",
    "\n",
    "    return img\n",
    "def test(checkpoint='./weights/face_paint_512_v2.pt',input_dir='./samples/camera/',output_dir='./samples/camera_result',upsample_align=False):\n",
    "    device = 'cpu'\n",
    "    net = Generator()\n",
    "    print(\"1\")\n",
    "    net.load_state_dict(torch.load(checkpoint, map_location=\"cpu\"))\n",
    "    net.to(device).eval()\n",
    "    print(f\"model loaded: {checkpoint}\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    img = cv2.imread('./等待界面.png')\n",
    "    frame = cv2.resize(img,(640,480))\n",
    "    #要注意这里不是通过array或者list格式输出的，为video包中的专属格式\n",
    "    outframe = hdmi_out.newframe()\n",
    "    outframe[0:480,0:640,:] = frame[0:480,0:640,[0,1,2]]\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    for image_name in sorted(os.listdir(input_dir)):\n",
    "        print(\"2\")\n",
    "        if os.path.splitext(image_name)[-1].lower() not in [\".jpg\", \".png\", \".bmp\", \".tiff\"]:\n",
    "            continue\n",
    "            \n",
    "        print(os.path.join(input_dir, image_name))\n",
    "        image = load_image(os.path.join(input_dir, image_name))\n",
    "        a,b = image.size\n",
    "        if(a>b):\n",
    "            image = image.resize((224,int(224/(a/b))))\n",
    "        else:\n",
    "            image = image.resize((int(224/(b/a)),224))\n",
    "        print(\"3\")\n",
    "        print(\"image size : \",image.size)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image = to_tensor(image).unsqueeze(0) * 2 - 1\n",
    "            print(\"4\")\n",
    "            out = net(image.to(device), upsample_align).cpu()\n",
    "            print(\"5\")\n",
    "            out = out.squeeze(0).clip(-1, 1) * 0.5 + 0.5\n",
    "            out = to_pil_image(out)\n",
    "\n",
    "        out.save(os.path.join(output_dir, image_name))\n",
    "        print(\"6\")\n",
    "        print(f\"image saved: {image_name}\")\n",
    "        img =cv2.imread(os.path.join(input_dir, image_name)) # 待处理的图片地址, 替换成你的地址就好\n",
    "        img2 =cv2.imread(os.path.join(output_dir, image_name)) # 待处理的图片地址, 替换成你的地址就好\n",
    "\n",
    "        if(img.shape[0]<img.shape[1]):\n",
    "            target_size=[240,640] # 目标图像大小\n",
    "            img = resize_img_keep_ratio(img, target_size) \n",
    "            img2 = resize_img_keep_ratio(img2, target_size) \n",
    "            new_img = np.concatenate([img2, img], axis=0)\n",
    "        else:\n",
    "            target_size=[480,320] # 目标图像大小\n",
    "            img = resize_img_keep_ratio(img, target_size) \n",
    "            img2 = resize_img_keep_ratio(img2, target_size) \n",
    "            new_img = np.concatenate([img2, img], axis=1)\n",
    "        \n",
    "        plt.imshow(new_img)\n",
    "\n",
    "        plt.title(\" Anime--->Image \",fontsize=15,c=\"royalblue\")\n",
    "        plt.axis ('off') \n",
    "        plt.savefig(os.path.join(output_dir, image_name[:-3]+\"png\"))\n",
    "        plt.show()\n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe[0:480,0:640,:] = new_img[0:480,0:640,[2,1,0]]\n",
    "        hdmi_out.writeframe(outframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c8a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo():\n",
    "    flag = 1\n",
    "    start = time.time()\n",
    "\n",
    "    while (flag):\n",
    "        ret, frame_vga = videoIn.read()\n",
    "        cur_time = time.time()\n",
    "#         print(ret)\n",
    "        if(int(cur_time-start)==3):\n",
    "            flag=0\n",
    "        if (ret):      \n",
    "            outframe = hdmi_out.newframe()\n",
    "            outframe[0:480,0:640,:] = frame_vga[0:480,0:640,:]\n",
    "            cv2.putText(outframe, \" Countdown Timer\"+str(int(cur_time-start))+\"s\",(0, 50), cv2.FONT_HERSHEY_PLAIN, 2.0, (29, 147, 219), 2)\n",
    "            hdmi_out.writeframe(outframe)\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to read from camera.\")\n",
    "    outframe = hdmi_out.newframe()\n",
    "    outframe[0:480,0:640,:] = frame_vga[0:480,0:640,:]\n",
    "    cv2.putText(outframe, \" Happy with the photo？\",(0, 50), cv2.FONT_HERSHEY_PLAIN, 2.0, (29, 147, 219), 2)\n",
    "    hdmi_out.writeframe(outframe)\n",
    "    happy=input(\" Happy with the photo？\")\n",
    "    return happy,frame_vga\n",
    "# 封装resize函数\n",
    "def resize_img_keep_ratio(img,target_size):\n",
    "#     img = cv2.imread(img_name) # 读取图片\n",
    "    b,g,r = cv2.split(img)\n",
    "    img = cv2.merge((r,g,b))\n",
    "    old_size= img.shape[0:2] # 原始图像大小\n",
    "    ratio = min(float(target_size[i])/(old_size[i]) for i in range(len(old_size))) # 计算原始图像宽高与目标图像大小的比例，并取其中的较小值\n",
    "    new_size = tuple([int(i*ratio) for i in old_size]) # 根据上边求得的比例计算在保持比例前提下得到的图像大小\n",
    "    img = cv2.resize(img,(new_size[1], new_size[0])) # 根据上边的大小进行放缩\n",
    "    pad_w = target_size[1] - new_size[1] # 计算需要填充的像素数目（图像的宽这一维度上）\n",
    "    pad_h = target_size[0] - new_size[0] # 计算需要填充的像素数目（图像的高这一维度上）\n",
    "    top,bottom = pad_h//2, pad_h-(pad_h//2)\n",
    "    left,right = pad_w//2, pad_w -(pad_w//2)\n",
    "    img_new = cv2.copyMakeBorder(img,top,bottom,left,right,cv2.BORDER_CONSTANT,None,(255,255,255)) \n",
    "    return img_new\n",
    "\n",
    "def main(scenery,from_camera,pic_address=None,output_dir='./samples/trans_results'):\n",
    "    if(scenery=='1'):\n",
    "        model_weight = './weights/paprika.pt'\n",
    "    elif(scenery=='0'):\n",
    "        model_weight = './weights/face_paint_512_v2.pt'\n",
    "    else:\n",
    "        model_weight = './weights/paprika.pt'\n",
    "    if(from_camera=='1'):\n",
    "        input_dir = \"./samples/need_trans/\"\n",
    "    else:\n",
    "        input_dir = os.path.dirname(pic_address)\n",
    "    if(from_camera=='1'):\n",
    "        happy=0\n",
    "        while(happy!='1'):\n",
    "            happy,frame_vga = photo()\n",
    "            outframe = hdmi_out.newframe()\n",
    "            outframe[0:480,0:640,:] = frame_vga[0:480,0:640,:]\n",
    "            hdmi_out.writeframe(outframe)\n",
    "        \n",
    "    if(scenery!='1'):\n",
    "        if(from_camera==\"1\"):\n",
    "            np_frame = frame_vga\n",
    "        else:\n",
    "            np_frame =  cv2.imread(pic_address)\n",
    "\n",
    "        face_cascade = cv2.CascadeClassifier(\n",
    "            '/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "            'haarcascade_frontalface_default.xml')\n",
    "        eye_cascade = cv2.CascadeClassifier(\n",
    "            '/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "            'haarcascade_eye.xml')\n",
    "\n",
    "        gray = cv2.cvtColor(np_frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        i=20\n",
    "        for (x,y,w,h) in faces:\n",
    "            new = np_frame[int(y*0.3):int(y+h*1.1),int(x):int(x+w),:]\n",
    "            path = \"./samples/need_trans/\"+str(i)+'.jpg'\n",
    "            i+=1\n",
    "            cv2.imwrite(path, new)     # 将图片保存为本地文件\n",
    "            plt.axis ('off') \n",
    "            plt.imshow(new[:,:,[2,1,0]])\n",
    "            plt.show()\n",
    "            img = cv2.imread(path)\n",
    "\n",
    "            #在图片上添加文字信息\n",
    "#             frame = cv2.resize(img,(640,480))\n",
    "            frame = resize_img_keep_ratio(img,(480,640))\n",
    "            cv2.putText(frame, \"The Portrait will be transport:\",(10, 50), cv2.FONT_HERSHEY_PLAIN, 2.0, (0, 0, 255), 2)\n",
    "        \n",
    "            outframe = hdmi_out.newframe()\n",
    "            outframe[0:480,0:640,:] = frame[0:480,0:640,[2,1,0]]\n",
    "            hdmi_out.writeframe(outframe)\n",
    "            time.sleep(3)\n",
    "\n",
    "            \n",
    "    start = time.time()\n",
    "    test(checkpoint=model_weight,input_dir=input_dir,output_dir=output_dir,upsample_align=False)\n",
    "    end = time.time()\n",
    "    print(end-start,\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b1cacc",
   "metadata": {},
   "source": [
    "## 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f542ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/xilinx/jupyter_notebooks/AnimeGAN/信息界面.png')\n",
    "#在图片上添加文字信息\n",
    "frame = cv2.resize(img,(640,480))\n",
    "scenery = input(\"What type do you want to transport? \\nPut 1 for Senery 0 for Portrait\\t\")\n",
    "#在图片上添加文字信息\n",
    "# frame = cv2.resize(img,(640,480))\n",
    "if(scenery=='1'):\n",
    "    cv2.putText(frame, \"Scenery or Portrait?\",(40, 100), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"You choose Scenery\",(40, 150), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 225, 255), 2)\n",
    "else:\n",
    "    cv2.putText(frame, \"Scenery or Portrait?\",(40, 100), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"You choose Portrait\",(40, 150), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 225, 255), 2)\n",
    "outframe = hdmi_out.newframe()\n",
    "outframe[0:480,0:640,:] = frame[0:480,0:640,[0,1,2]]\n",
    "hdmi_out.writeframe(outframe)\n",
    "from_camera = input(\"Do you want take a photo now or select a picture from folder? \\nPut 0 for from folder 1 for take a picture now\")\n",
    "if(from_camera=='1'):\n",
    "    cv2.putText(frame, \"Take a photo or Select one from folder?\",(40, 200), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"You choose take photo now\",(40, 250), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 255), 2)\n",
    "else:\n",
    "    cv2.putText(frame, \"Take a photo or Select one from folder?\",(40, 200), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"You choose to get a photo from folder\",(40,250), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 225, 255), 2)\n",
    "outframe = hdmi_out.newframe()\n",
    "outframe[0:480,0:640,:] = frame[0:480,0:640,[0,1,2]]\n",
    "hdmi_out.writeframe(outframe)\n",
    "hdmi_out.writeframe(outframe)\n",
    "if(from_camera==\"0\"):\n",
    "    pic_address = input(\"Please input the address of the picture which you want to transport:\")\n",
    "    cv2.putText(frame, \"The address is \"+pic_address,(40,300), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "    outframe = hdmi_out.newframe()\n",
    "    outframe[0:480,0:640,:] = frame[0:480,0:640,[0,1,2]]\n",
    "    hdmi_out.writeframe(outframe)\n",
    "else:\n",
    "    pic_address= None\n",
    "main(scenery,from_camera,pic_address)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
